{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사생활을 보호하는 딥러닝에 필요한 기본 인프라를 만드는 `포인터 텐서`에 대해 배웠습니다. 이번 섹션에서는 이러한 기본 도구를 이용하여 `첫 사생활 보호 딥러닝 알고리즘`인 `연합 학습을 구현하는 방법`에 대해 살펴볼 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연합 학습이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 연합 학습이란 딥러닝 모델을 학습하는 간단하고 강력한 방법입니다. 학습 데이터는 항상 일종의 수집 프로세스의 결과입니다. 사람들은 (각종 도구를 이용해) 실제 생활에서 이벤트를 기록하면서 데이터를 생성합니다. 일반적으로 이 데이터는 머신러닝 모델을 학습할 수 있도록 중앙의 한 곳으로 집계됩니다. 연합 학습은 이 방식을 완전히 바꿔놓습니다.\n",
    "\n",
    "---\n",
    "\n",
    "![image.png](https://blog.openmined.org/content/images/2019/02/Capture-d-e-cran-2019-02-25-a--17.45.36.png)\n",
    "\n",
    "학습 데이터를 모델(중앙 서버)로 가져오는 대신에 **모델을 학습 데이터(사용 가능한 모든 곳)**로 가져가게 됩니다.\n",
    "\n",
    "이를 통해 **데이터를 만드는 사람만이 영구 사본의 소유자가 되어서 액세스 권한이 있는 사람들을 제어**할 수 있게 됩니다. 근사하죠?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1 - 간단한 연합 학습 예제\n",
    "--- \n",
    "\n",
    "연합학습을 다루기 전, 기존 중앙집중형식의 학습 방법을 다루보고 이와 비교해보자. \n",
    "\n",
    "먼저 **기존 학습 방법**에서 필요한 것은 다음과 같다.\n",
    "\n",
    "- 간단한 데이터 셋\n",
    "- 모델\n",
    "- 데이터를 맞추기 위해 모델을 학습시키기 위한 몇 가지 기본 학습 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Model\n",
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Training Logic\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(20):\n",
    "\n",
    "        # 1) erase previous gradients (if they exist)\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # 2) make a prediction\n",
    "        pred = model(data)\n",
    "\n",
    "        # 3) calculate how much we missed\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        # 4) figure out which weights caused us to miss\n",
    "        loss.backward()\n",
    "\n",
    "        # 5) change those weights\n",
    "        opt.step()\n",
    "\n",
    "        # 6) print our progress\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3529)\n",
      "tensor(0.2463)\n",
      "tensor(0.1801)\n",
      "tensor(0.1329)\n",
      "tensor(0.0986)\n",
      "tensor(0.0734)\n",
      "tensor(0.0549)\n",
      "tensor(0.0412)\n",
      "tensor(0.0310)\n",
      "tensor(0.0234)\n",
      "tensor(0.0177)\n",
      "tensor(0.0134)\n",
      "tensor(0.0101)\n",
      "tensor(0.0077)\n",
      "tensor(0.0059)\n",
      "tensor(0.0045)\n",
      "tensor(0.0034)\n",
      "tensor(0.0026)\n",
      "tensor(0.0020)\n",
      "tensor(0.0015)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완성입니다! 우리는 전통적인 방식으로 기본 모델을 학습시켰습니다. 모든 데이터는 로컬 컴퓨터로 집계되었으며 이를 사용하여 모델을 업데이트할 수 있습니다. 하지만 연합 학습은 이 방식으로 작동하지 않습니다. \n",
    "\n",
    "---\n",
    "\n",
    "이 예제를 **연합 학습 방식으로 수정해 보자.**\n",
    "\n",
    "그래서 우리가 필요한 것은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 몇 개의 작업자 만들기\n",
    "- 각 작업자의 학습 데이터에 대한 포인터를 얻기\n",
    "- 연합 학습을 수행하기 위해 업데이트 된 학습 방법\n",
    "\n",
    "    새로운 학습 단계:\n",
    "\n",
    "    - 작업자에게 모델을 보냅니다.\n",
    "    - 거기에 있는 데이터를 학습시킵니다.\n",
    "    - 모델을 다시 가져오고 다음 작업자에서 이를 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to bob and alice\n",
    "data_bob = data[0:2]\n",
    "target_bob = target[0:2]\n",
    "\n",
    "data_alice = data[2:]\n",
    "target_alice = target[2:]\n",
    "\n",
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)\n",
    "\n",
    "data_bob = data_bob.send(bob)\n",
    "data_alice = data_alice.send(alice)\n",
    "target_bob = target_bob.send(bob)\n",
    "target_alice = target_alice.send(alice)\n",
    "\n",
    "# organize pointers into a list\n",
    "datasets = [(data_bob,target_bob),(data_alice,target_alice)]\n",
    "\n",
    "opt = optim.SGD(params=model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Training Logic\n",
    "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
    "    for iter in range(10):\n",
    "        \n",
    "        # NEW) iterate through each worker's dataset\n",
    "        for data,target in datasets:\n",
    "            print('----------------------------------------------------------')\n",
    "            print(\"data를 {0}에서 {1}로 보냄 \".format(data.owner, data.location))\n",
    "            # NEW) send model to correct worker (# model 사전 정의 필요)\n",
    "            model.send(data.location)\n",
    "\n",
    "            # 1) erase previous gradients (if they exist)\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # 2) make a prediction\n",
    "            pred = model(data)\n",
    "\n",
    "            # 3) calculate how much we missed\n",
    "            loss = ((pred - target)**2).sum()\n",
    "\n",
    "            # 4) figure out which weights caused us to miss\n",
    "            loss.backward()\n",
    "\n",
    "            # 5) change those weights\n",
    "            opt.step()\n",
    "            \n",
    "            # NEW) get model (with gradients)\n",
    "            model.get()\n",
    "\n",
    "            # 6) print our progress\n",
    "            print(loss.get()) # NEW) slight edit... need to call .get() on loss\\\n",
    "    \n",
    "# federated averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(1.5504e-05, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(1.0409e-05, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(9.0866e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(6.3690e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(5.3755e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(3.9363e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(3.2187e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(2.4607e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(1.9571e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(1.5577e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(1.2122e-06, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(9.9933e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(7.6696e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(6.5024e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(4.9679e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(4.2931e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(3.2971e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(2.8753e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:bob #objects:6>로 보냄 \n",
      "tensor(2.2412e-07, requires_grad=True)\n",
      "----------------------------------------------------------\n",
      "data를 <VirtualWorker id:me #objects:0>에서 <VirtualWorker id:alice #objects:6>로 보냄 \n",
      "tensor(1.9528e-07, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 절차\n",
    "\n",
    "1. 모델을 각 `worker`에게 보낸다.\n",
    "2. 각 `worker`는 새로운 `gradient` 계산\n",
    "3. 각 `worker`에서 새롭게 계산된 `gradient`를 `local server`로 가져와 `global model` 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 예제의 단점\n",
    "\n",
    "이 예제는 연합 학습에 대한 좋은 소개이지만 여전히 몇 가지 중요한 단점이 있습니다. 특히 model.get() 를 호출하고 Bob 또는 Alice로부터 업데이트 된 모델을 수신하면 실제로 우리는 그 그래디언트를 보면서 Bob과 Alice의 학습 데이터에 대해 많은 것을 배울 수 있습니다. 경우에 따라 학습 데이터를 완벽하게 복원도 가능합니다!\n",
    "\n",
    "그래서 어떻게 해야할까요? 음, 사람들이 사용하는 첫번째 전략으로는 중앙 서버에 업로드하기 전에 여러 개인의 그래디언트를 평균화하는 것입니다. 그러나 이 전략을 사용하려면 PointerTensor 객체를 좀 더 정교하게 사용해야 합니다. 다음 섹션에서는 포인터의 고급 기능에 대해 배우고 연합 학습 예제를 업그레이드하도록 하겠습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
